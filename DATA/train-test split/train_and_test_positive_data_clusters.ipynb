{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import re\n","import pandas as pd\n","from google.colab import drive\n","import copy\n","from collections import Counter"],"metadata":{"id":"tU3InOERvEL4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xn8R-SQZw33c","outputId":"d1e569c1-a552-499c-9ffb-afcc2fd09af3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["distances = pd.read_csv('/content/drive/MyDrive/פרויקט גמר/DATA/train and test/distance.csv', header=None)\n","clusters_info = '/content/drive/MyDrive/פרויקט גמר/DATA/train and test/est_all_data.clstr'"],"metadata":{"id":"vuZmVuWLxCtt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### extracting the clusters"],"metadata":{"id":"a9IkKKac05ku"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RLkjmq6Cuht0"},"outputs":[],"source":["def parse_cluster_file(file_path):\n","    \"\"\"\n","    Parses a cluster file and extracts cluster information into a dictionary.\n","\n","    Parameters:\n","    file_path (str): The path to the cluster file.\n","\n","    Returns:\n","    dict: A dictionary where keys are cluster identifiers and values are lists of lists.\n","          Each inner list contains species, chromosome, and identifier information.\n","    \"\"\"\n","    clusters = {}\n","    current_cluster = None\n","\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            line = line.strip()\n","            if line.startswith(\">Cluster\"):\n","                current_cluster = line[1:]\n","                clusters[current_cluster] = []\n","            else:\n","                match = re.search(r', >(.*)', line)\n","                if match and current_cluster is not None:\n","                    value = match.group(1)\n","                    parts = value.split('|')\n","                    species = parts[0]\n","                    rest = parts[1].split('/')\n","                    chromosome = rest[0]\n","                    identifier = rest[1]\n","                    clusters[current_cluster].append([species, chromosome, identifier])\n","    return clusters"]},{"cell_type":"code","source":["clusters = parse_cluster_file(clusters_info)"],"metadata":{"id":"CTQZ4LttxN-h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### putting the clusters bigger then 1 in train"],"metadata":{"id":"qzL5Lrb70_aV"}},{"cell_type":"code","source":["train_initial = []\n","all_other = []\n","# first extract all clusters greater then 1\n","for c in list(clusters.items()):\n","  k = c[0]\n","  v = c[1]\n","  if len(v) > 1:\n","    train_initial.append(v)\n","  else:\n","    all_other.append(v)\n","\n","# now, split the sub list such that 'train' will be a list of lists\n","train = []\n","for i in train_initial:\n","  for sublist in i:\n","    train.append(sublist)"],"metadata":{"id":"Cg4EbXubyiHq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### extracting from distances all records that apear in the train - then putting them also in train"],"metadata":{"id":"RMK0LBbm1iNI"}},{"cell_type":"code","source":["rows_list = distances.values.tolist()"],"metadata":{"id":"0IrIxMTB3DzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_ids_from_rows(rows_list):\n","    \"\"\"\n","    Extracts specific identifiers from a list of rows.\n","\n","    Parameters:\n","    rows_list (list of lists): The input list where each sub-list contains species, chromosome, and identifier information.\n","\n","    Returns:\n","    list of lists: A cleaned list where each sub-list contains species, chromosome, and extracted identifiers.\n","    \"\"\"\n","    cleaned_rows = []\n","    id_pattern = re.compile(r\"'>(FP\\d+)'\")\n","\n","    for lst in rows_list:\n","        tmp = [lst[0], lst[1]]  # Append the first element (species) and second element (chromosome)\n","        for vals in lst[2:]:  # Start from the third element\n","            if isinstance(vals, str):\n","                match = id_pattern.search(vals)\n","                if match:\n","                    tmp.append(match.group(1))\n","        cleaned_rows.append(tmp)\n","\n","    return cleaned_rows\n","\n","cleaned_rows = extract_ids_from_rows(rows_list)"],"metadata":{"id":"V_JxXdwg4mjT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["making a train doctionary for easier working"],"metadata":{"id":"vsQzOMpOhdOh"}},{"cell_type":"code","source":["train_dict = {}\n","for seq in train:\n","  org = seq[0]\n","  id = seq[2]\n","  if org not in train_dict.keys():\n","    train_dict[org] = [id]\n","  else:\n","    train_dict[org].append(id)"],"metadata":{"id":"jMcmBdbs57bQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["now searching in the distance if to put in train"],"metadata":{"id":"Slfedy73hf3s"}},{"cell_type":"code","source":["for row in cleaned_rows:\n","  org = row[0]\n","  chromo = row[1]\n","  ids = row[2:]\n","  # iterate over the ids\n","  for i in ids:\n","    # if id in train already - then we need to put all ids in the row also\n","    if i in train_dict[org]:\n","      tmp = [j for j in ids]  # all other ids\n","      for t in tmp:\n","        if t not in train_dict[org]:\n","          train.append([org, chromo, t])\n","    else:\n","      all_other.append([org, chromo, i])"],"metadata":{"id":"npANmFkRhapK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["make the dict again"],"metadata":{"id":"o4ilfWF4A5Rd"}},{"cell_type":"code","source":["train_dict = {}\n","for seq in train:\n","  org = seq[0]\n","  id = seq[2]\n","  if org not in train_dict.keys():\n","    train_dict[org] = [id]\n","  else:\n","    train_dict[org].append(id)"],"metadata":{"id":"07dt57W3mSks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_other = [i[0] for i in all_other]"],"metadata":{"id":"9tOgPyjij3c-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["now we have:\n","\n","* train : a list of all records needs to be on train\n","* all_other : a list of all records to be split to either train or test"],"metadata":{"id":"WReujt9zkulR"}},{"cell_type":"markdown","source":["## creating tata and non tata train and test"],"metadata":{"id":"T1QWPWgNlRJu"}},{"cell_type":"code","source":["tata_df = pd.read_csv('/content/drive/MyDrive/פרויקט גמר/DATA/combined positive data/TATA_combined_df.csv')\n","non_tata_df = pd.read_csv('/content/drive/MyDrive/פרויקט גמר/DATA/combined positive data/non_TATA_combined_df.csv')"],"metadata":{"id":"LZoEHt13CEF6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["we need to remove 'mellifera'"],"metadata":{"id":"mOMAOntoG-nL"}},{"cell_type":"code","source":["del train_dict['mellifera']"],"metadata":{"id":"VuJ-y5LTBc7l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["creating 2 lists - to see which items in train are tata and which are non-tata"],"metadata":{"id":"uat_5XOjHDMo"}},{"cell_type":"code","source":["cleaned_dict = {key: list(set(value)) for key, value in train_dict.items()}\n","train_dict = cleaned_dict"],"metadata":{"id":"AIRDelrh0UcF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["this cell takes 15 min"],"metadata":{"id":"srKpWS0tWgJo"}},{"cell_type":"code","source":["tata_train = []\n","non_tata_train = []\n","\n","for organism, id_list in train_dict.items():\n","    for id in id_list:\n","        # Check if record is in tata_df\n","        if not tata_df[(tata_df['organism'] == organism) & (tata_df['ID'] == id)].empty:\n","            tata_train.append((organism, id))\n","        # Check if record is in non_tata_df\n","        elif not non_tata_df[(non_tata_df['organism'] == organism) & (non_tata_df['ID'] == id)].empty:\n","            non_tata_train.append((organism, id))"],"metadata":{"id":"p67remmfAhky"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tata_train = list(set(tata_train))\n","non_tata_train = list(set(non_tata_train))"],"metadata":{"id":"hQlg-rRi0cX6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["TATA"],"metadata":{"id":"fuXFRYwK7Ukl"}},{"cell_type":"code","source":["grouped_dict_tata = {}\n","\n","# Group by organism\n","for organism, id in tata_train:\n","    if organism not in grouped_dict_tata.keys():\n","        grouped_dict_tata[organism] = []\n","    grouped_dict_tata[organism].append(id)"],"metadata":{"id":"JDnwjTuuGzR6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["grouped_dict_non_tata = {}\n","\n","# Group by organism\n","for organism, id in non_tata_train:\n","    if organism not in grouped_dict_non_tata.keys():\n","        grouped_dict_non_tata[organism] = []\n","    grouped_dict_non_tata[organism].append(id)"],"metadata":{"id":"JgRnIf1dH0Vr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dict_tata = {}"],"metadata":{"id":"wwNNWwMMK77L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"CURRENT TRAINING DATA:\")\n","print()\n","\n","print(\"----------------TATA----------------\")\n","\n","for k,v in grouped_dict_tata.items():\n","  print(\"in\", k, \"we have\", len(v), \"items\")\n","\n","print()\n","print(\"----------------NON-TATA----------------\")\n","for k,v in grouped_dict_non_tata.items():\n","  print(\"in\", k, \"we have\", len(v), \"items\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9rJ8lSSLT9B","outputId":"4873df3b-e1a0-4ae3-f43d-c30f6ecf4e91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CURRENT TRAINING DATA:\n","\n","----------------TATA----------------\n","in human we have 2045 items\n","in norvegicus we have 1544 items\n","in melanogaster we have 286 items\n","in musculus we have 2408 items\n","in mulatta we have 614 items\n","in celegans we have 182 items\n","in rerio we have 136 items\n","in gallus we have 42 items\n","\n","----------------NON-TATA----------------\n","in celegans we have 522 items\n","in musculus we have 7974 items\n","in mulatta we have 5486 items\n","in human we have 9869 items\n","in melanogaster we have 887 items\n","in norvegicus we have 5943 items\n","in gallus we have 242 items\n","in rerio we have 139 items\n"]}]},{"cell_type":"code","source":["print(\"INFO ABOUT REAL AMOUNT IN EACH ORGANISM\")\n","print(\"----------------TATA----------------\")\n","print()\n","for name in grouped_dict_tata.keys():\n","  tmp_df = tata_df[tata_df['organism'] == name]\n","  print(\"in\", name, \"we have total of\", len(tmp_df), \"items. and 80% will be\", int(0.8*len(tmp_df)))\n","\n","print()\n","print(\"----------------NON-TATA----------------\")\n","print()\n","for name in grouped_dict_non_tata.keys():\n","  tmp_df = non_tata_df[non_tata_df['organism'] == name]\n","  print(\"in\", name, \"we have total of\", len(tmp_df), \"items. and 80% will be\", int(0.8*len(tmp_df)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jHgN3rXSL-3Y","outputId":"fadb39a7-097d-4ff0-dce8-faa2e3e9c386"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO ABOUT REAL AMOUNT IN EACH ORGANISM\n","----------------TATA----------------\n","\n","in human we have total of 3065 items. and 80% will be 2452\n","in norvegicus we have total of 1707 items. and 80% will be 1365\n","in melanogaster we have total of 2598 items. and 80% will be 2078\n","in musculus we have total of 3305 items. and 80% will be 2644\n","in mulatta we have total of 631 items. and 80% will be 504\n","in celegans we have total of 1013 items. and 80% will be 810\n","in rerio we have total of 2131 items. and 80% will be 1704\n","in gallus we have total of 674 items. and 80% will be 539\n","\n","----------------NON-TATA----------------\n","\n","in celegans we have total of 6107 items. and 80% will be 4885\n","in musculus we have total of 21805 items. and 80% will be 17444\n","in mulatta we have total of 7701 items. and 80% will be 6160\n","in human we have total of 26533 items. and 80% will be 21226\n","in melanogaster we have total of 14372 items. and 80% will be 11497\n","in norvegicus we have total of 10894 items. and 80% will be 8715\n","in gallus we have total of 5452 items. and 80% will be 4361\n","in rerio we have total of 8597 items. and 80% will be 6877\n"]}]},{"cell_type":"code","source":["grouped_dict_tata_copy = copy.deepcopy(grouped_dict_tata)"],"metadata":{"id":"onUBKICxX4CL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name in grouped_dict_tata_copy.keys():\n","    # Extract only the rows with specific organism\n","    tmp_df = tata_df[tata_df['organism'] == name]\n","    threshold = 0.8 * len(tmp_df)  # Number for the training amount\n","    curr = len(grouped_dict_tata_copy[name])\n","\n","    for index, row in tmp_df.iterrows():\n","        organism = row['organism']\n","        id = row['ID']\n","\n","        if id not in grouped_dict_tata_copy[name]:\n","          if curr < threshold-1:  # Then we can add it to the train\n","              grouped_dict_tata_copy[name].append(id)\n","              curr += 1\n","          else:  # We already have 80% in the train - then add to the test set\n","              if name not in test_dict_tata.keys():\n","                  test_dict_tata[name] = [id]\n","              else:\n","                  test_dict_tata[name].append(id)"],"metadata":{"id":"EHes9EG8H5WB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for k,v in test_dict_tata.items():\n","  data = []\n","  for id in v:\n","    tmp = tata_df[(tata_df['organism'] == k) & (tata_df['ID'] == id)]['seq'].iloc[0]\n","    data.append({'name': k, 'id': id, 'seq': tmp})\n","  df = pd.DataFrame(data)\n","  df.to_csv(f'{k}_tata_test.csv')"],"metadata":{"id":"aKMmS2f01VAu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for k,v in grouped_dict_tata_copy.items():\n","  data = []\n","  for id in v:\n","    tmp = tata_df[(tata_df['organism'] == k) & (tata_df['ID'] == id)]['seq'].iloc[0]\n","    data.append({'name': k, 'id': id, 'seq': tmp})\n","  df = pd.DataFrame(data)\n","  df.to_csv(f'{k}_tata_train.csv')"],"metadata":{"id":"Gpo5vifP5Vuw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"CURRENT TRAINING INFO\")\n","print(\"----------------TATA----------------\")\n","print()\n","for name in grouped_dict_tata_copy.keys():\n","  print(\"in\", name, \"we have total of\", len(grouped_dict_tata_copy[name]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zl4gdamAY049","outputId":"7dffae7d-e94b-4fe6-e825-153843e866ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CURRENT TRAINING INFO\n","----------------TATA----------------\n","\n","in human we have total of 2451\n","in norvegicus we have total of 1544\n","in melanogaster we have total of 2078\n","in musculus we have total of 2643\n","in mulatta we have total of 614\n","in celegans we have total of 810\n","in rerio we have total of 1704\n","in gallus we have total of 539\n"]}]},{"cell_type":"code","source":["print(\"INFO ABOUT REAL AMOUNT IN EACH ORGANISM\")\n","print(\"----------------TATA TEST----------------\")\n","print()\n","for name in test_dict_tata.keys():\n","  print(\"in\", name, \"we have total of\", len(test_dict_tata[name]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UVu6J4q_ZLuC","outputId":"e4b21d1c-6468-4c3c-cbbb-5ba60c3b5f97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO ABOUT REAL AMOUNT IN EACH ORGANISM\n","----------------TATA TEST----------------\n","\n","in human we have total of 614\n","in norvegicus we have total of 163\n","in melanogaster we have total of 520\n","in musculus we have total of 662\n","in mulatta we have total of 17\n","in celegans we have total of 203\n","in rerio we have total of 427\n","in gallus we have total of 135\n"]}]},{"cell_type":"markdown","source":["non-TATA"],"metadata":{"id":"EceuM11H7Qx2"}},{"cell_type":"code","source":["grouped_dict_non_tata = {}\n","\n","# Group by organism\n","for organism, id in non_tata_train:\n","    if organism not in grouped_dict_non_tata.keys():\n","        grouped_dict_non_tata[organism] = []\n","    grouped_dict_non_tata[organism].append(id)"],"metadata":{"id":"DOAuzags7SL0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dict_non_tata = {}"],"metadata":{"id":"UTK3I-e47SL1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["grouped_dict_non_tata_copy = copy.deepcopy(grouped_dict_non_tata)"],"metadata":{"id":"zGajPXtH7SL1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name in grouped_dict_non_tata_copy.keys():\n","    # Extract only the rows with specific organism\n","    tmp_df = non_tata_df[non_tata_df['organism'] == name]\n","    threshold = 0.8 * len(tmp_df)  # Number for the training amount\n","    curr = len(grouped_dict_non_tata_copy[name])\n","\n","    for index, row in tmp_df.iterrows():\n","        organism = row['organism']\n","        id = row['ID']\n","\n","        if id not in grouped_dict_non_tata_copy[name]:\n","          if curr < threshold-1:  # Then we can add it to the train\n","              grouped_dict_non_tata_copy[name].append(id)\n","              curr += 1\n","          else:  # We already have 80% in the train - then add to the test set\n","              if name not in test_dict_non_tata.keys():\n","                  test_dict_non_tata[name] = [id]\n","              else:\n","                  test_dict_non_tata[name].append(id)"],"metadata":{"id":"gDG3Oc1T7SL1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["this cell takes 34 min"],"metadata":{"id":"F4lHXj_lWngd"}},{"cell_type":"code","source":["for k,v in grouped_dict_non_tata_copy.items():\n","  data = []\n","  for id in v:\n","    tmp = non_tata_df[(non_tata_df['organism'] == k) & (non_tata_df['ID'] == id)]['seq'].iloc[0]\n","    data.append({'name': k, 'id': id, 'seq': tmp})\n","  df = pd.DataFrame(data)\n","  df.to_csv(f'{k}_non_tata_train.csv')"],"metadata":{"id":"T1wXjCk17SL1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["this cell takes 7 min"],"metadata":{"id":"0HwGFHm2WpHn"}},{"cell_type":"code","source":["for k,v in test_dict_non_tata.items():\n","  data = []\n","  for id in v:\n","    tmp = non_tata_df[(non_tata_df['organism'] == k) & (non_tata_df['ID'] == id)]['seq'].iloc[0]\n","    data.append({'name': k, 'id': id, 'seq': tmp})\n","  df = pd.DataFrame(data)\n","  df.to_csv(f'{k}_non_tata_test.csv')"],"metadata":{"id":"Hg-gT6e97SL1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"CURRENT TRAINING INFO\")\n","print(\"----------------non-TATA----------------\")\n","print()\n","for name in grouped_dict_non_tata_copy.keys():\n","  print(\"in\", name, \"we have total of\", len(grouped_dict_non_tata_copy[name]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4204c000-e8e9-4331-819d-b8176762f390","id":"bViL-p9b7z3I"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CURRENT TRAINING INFO\n","----------------non-TATA----------------\n","\n","in celegans we have total of 4885\n","in musculus we have total of 17443\n","in mulatta we have total of 6160\n","in human we have total of 21226\n","in melanogaster we have total of 11497\n","in norvegicus we have total of 8715\n","in gallus we have total of 4361\n","in rerio we have total of 6877\n"]}]},{"cell_type":"code","source":["print(\"INFO ABOUT REAL AMOUNT IN EACH ORGANISM\")\n","print(\"----------------nn-TATA TEST----------------\")\n","print()\n","for name in test_dict_non_tata.keys():\n","  print(\"in\", name, \"we have total of\", len(test_dict_non_tata[name]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6ee94bbd-27d0-4401-ed5b-032e1a24d6a7","id":"_cVI9cAm7z3I"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO ABOUT REAL AMOUNT IN EACH ORGANISM\n","----------------nn-TATA TEST----------------\n","\n","in celegans we have total of 1222\n","in musculus we have total of 4362\n","in mulatta we have total of 1541\n","in human we have total of 5307\n","in melanogaster we have total of 2875\n","in norvegicus we have total of 2179\n","in gallus we have total of 1091\n","in rerio we have total of 1720\n"]}]},{"cell_type":"markdown","source":["#### Validation"],"metadata":{"id":"wiLvfmDX97Ep"}},{"cell_type":"code","source":["celegans_train_tata = pd.read_csv('/content/train_tata/celegans_tata_train.csv')\n","gullus_train_tata = pd.read_csv('/content/train_tata/gallus_tata_train.csv')\n","human_train_tata = pd.read_csv('/content/train_tata/human_tata_train.csv')\n","melanogaster_train_tata = pd.read_csv('/content/train_tata/melanogaster_tata_train.csv')\n","mulata_train_tata = pd.read_csv('/content/train_tata/mulatta_tata_train.csv')\n","musculus_train_tata = pd.read_csv('/content/train_tata/musculus_tata_train.csv')\n","norvegicus_train_tata = pd.read_csv('/content/train_tata/norvegicus_tata_train.csv')\n","rerio_train_tata = pd.read_csv('/content/train_tata/rerio_tata_train.csv')\n","\n","\n","celegans_train_non_tata = pd.read_csv('/content/celegans_non_tata_train.csv')\n","gullus_train_non_tata = pd.read_csv('/content/gallus_non_tata_train.csv')\n","human_train_non_tata = pd.read_csv('/content/human_non_tata_train.csv')\n","melanogaster_train_non_tata = pd.read_csv('/content/melanogaster_non_tata_train.csv')\n","mulata_train_non_tata = pd.read_csv('/content/mulatta_non_tata_train.csv')\n","musculus_train_non_tata = pd.read_csv('/content/musculus_non_tata_train.csv')\n","norvegicus_train_non_tata = pd.read_csv('/content/musculus_non_tata_train.csv')\n","rerio_train_non_tata = pd.read_csv('/content/rerio_non_tata_train.csv')"],"metadata":{"id":"jnsiWGIw992T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combined_train_tata = pd.concat([celegans_train_tata,gullus_train_tata,human_train_tata,melanogaster_train_tata,mulata_train_tata,musculus_train_tata,norvegicus_train_tata,rerio_train_tata])"],"metadata":{"id":"tul7uqqYAhwI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combined_train_non_tata = pd.concat([celegans_train_non_tata,gullus_train_non_tata,human_train_non_tata,melanogaster_train_non_tata,mulata_train_non_tata,musculus_train_non_tata,norvegicus_train_non_tata,rerio_train_non_tata])"],"metadata":{"id":"3afFomNmA6w-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# make new dict from distances\n","new_dict = {}\n","for row in cleaned_rows:\n","  org = row[0]\n","  chromo = row[1]\n","  ids = row[2:]\n","  if org not in new_dict.keys():\n","    new_dict[org] = [ids]\n","  else:\n","    new_dict[org].append(ids)"],"metadata":{"id":"JNnJytci_uMW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["TATA"],"metadata":{"id":"nuHEMclVUlEd"}},{"cell_type":"code","source":["new_train_tata, new_val_tata = {}, {}\n","\n","for name in new_dict.keys():\n","    new_train_tata[name] = []\n","    new_val_tata[name] = []\n","    distances = new_dict[name]\n","\n","    for d in distances:\n","      tmp = False\n","      for i in d:\n","        if i in list(combined_train_tata[combined_train_tata['name'] == name]['id']):\n","          tmp = True\n","        else:\n","          tmp=False\n","          break\n","      if tmp:\n","          if len(new_train_tata[name]) < int(0.8 * len(combined_train_tata[combined_train_tata['name'] == name])):\n","              for i in d:\n","                  new_train_tata[name].append(i)\n","          else:\n","              for i in d:\n","                  new_val_tata[name].append(i)\n","      else:\n","        break"],"metadata":{"id":"HtaYKKupGoEY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name in set(list(combined_train_tata['name'])):\n","  tmp = combined_train_tata[combined_train_tata['name'] == name]\n","  for index, row in tmp.iterrows():\n","    id = row['id']\n","    seq = row['seq']\n","    if id in new_train_tata[name] or id in new_val_tata[name]:\n","      continue\n","    else:\n","      if len(new_train_tata[name]) < 0.8 * len(combined_train_tata[combined_train_tata['name'] == name]):\n","        new_train_tata[name].append(id)\n","      else:\n","        new_val_tata[name].append(id)"],"metadata":{"id":"uFRwmeTRLMlV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["non - TATA"],"metadata":{"id":"XDT7Fv0yUjO_"}},{"cell_type":"code","source":["new_train_non_tata, new_val_non_tata = {}, {}\n","\n","for name in new_dict.keys():\n","    new_train_non_tata[name] = []\n","    new_val_non_tata[name] = []\n","    distances = new_dict[name]\n","\n","    for d in distances:\n","      tmp = False\n","      for i in d:\n","        if i in list(combined_train_non_tata[combined_train_non_tata['name'] == name]['id']):\n","          tmp = True\n","        else:\n","          tmp=False\n","          break\n","      if tmp:\n","          if len(new_train_non_tata[name]) < int(0.8 * len(combined_train_non_tata[combined_train_non_tata['name'] == name])):\n","              for i in d:\n","                  new_train_non_tata[name].append(i)\n","          else:\n","              for i in d:\n","                  new_val_non_tata[name].append(i)\n","      else:\n","        break"],"metadata":{"id":"rvjgEa5JUiCC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name in set(list(combined_train_non_tata['name'])):\n","  tmp = combined_train_non_tata[combined_train_non_tata['name'] == name]\n","  for index, row in tmp.iterrows():\n","    id = row['id']\n","    seq = row['seq']\n","    if id in new_train_non_tata[name] or id in new_val_non_tata[name]:\n","      continue\n","    else:\n","      if len(new_train_non_tata[name]) < 0.8 * len(combined_train_non_tata[combined_train_non_tata['name'] == name]):\n","        new_train_non_tata[name].append(id)\n","      else:\n","        new_val_non_tata[name].append(id)"],"metadata":{"id":"drbKWN54UiCC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["save to csv"],"metadata":{"id":"nSsHaU8EVVhI"}},{"cell_type":"code","source":["for k,v in new_train_tata.items():\n","  data = []\n","  for id in v:\n","    tmp = tata_df[(tata_df['organism'] == k) & (tata_df['ID'] == id)]['seq'].iloc[0]\n","    data.append({'name': k, 'id': id, 'seq': tmp})\n","  df = pd.DataFrame(data)\n","  df.to_csv(f'{k}_tata_new_train.csv')"],"metadata":{"id":"V9HxXrjOVWbM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for k,v in new_val_tata.items():\n","  data = []\n","  for id in v:\n","    tmp = tata_df[(tata_df['organism'] == k) & (tata_df['ID'] == id)]['seq'].iloc[0]\n","    data.append({'name': k, 'id': id, 'seq': tmp})\n","  df = pd.DataFrame(data)\n","  df.to_csv(f'{k}_tata_new_val.csv')"],"metadata":{"id":"kK7DuBQoV-lY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["this cell takes 23 min"],"metadata":{"id":"RytQFbFfjSdI"}},{"cell_type":"code","source":["for k,v in new_train_non_tata.items():\n","  data = []\n","  for id in v:\n","    tmp = non_tata_df[(non_tata_df['organism'] == k) & (non_tata_df['ID'] == id)]['seq'].iloc[0]\n","    data.append({'name': k, 'id': id, 'seq': tmp})\n","  df = pd.DataFrame(data)\n","  df.to_csv(f'{k}_non_tata_new_train.csv')"],"metadata":{"id":"BPJ7FIATWEd7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for k,v in new_val_non_tata.items():\n","  data = []\n","  for id in v:\n","    tmp = non_tata_df[(non_tata_df['organism'] == k) & (non_tata_df['ID'] == id)]['seq'].iloc[0]\n","    data.append({'name': k, 'id': id, 'seq': tmp})\n","  df = pd.DataFrame(data)\n","  df.to_csv(f'{k}_non_tata_new_val.csv')"],"metadata":{"id":"Xgt7ZMZaWKQB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Genome"],"metadata":{"id":"JVej-i1XByY0"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","genome_neg_merged = pd.read_csv('/content/drive/MyDrive/פרויקט גמר/DATA/negative genome files/merged_negative_genome.csv')\n","train_df, test_df = train_test_split(genome_neg_merged, test_size=0.2, random_state=42)\n","\n","train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"],"metadata":{"id":"8-_2PEQzBz2y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.to_csv('train_df_genome.csv')\n","test_df.to_csv('test_df_genome.csv')\n","val_df.to_csv('val_df_genome.csv')"],"metadata":{"id":"PAhgajQtPZq3"},"execution_count":null,"outputs":[]}]}